# 数据采样方案 - 开发笔记

## 文档信息

- **创建时间**: 2025-07-02
- **文档类型**: 数据处理方案
- **目标**: 生成6000条BERT训练数据
- **状态**: 方案已确认，待执行

## 项目背景

### 目标

为Bert+LoRa模型训练生成标准化的数据集，包含6000条标注数据，支持三层内容过滤系统的第二层语义理解。

### 数据规模

- **目标样本数**: 6000条
- **数据来源**: 400万论坛帖子
- **标注方式**: 人工审核 + LLM诊断 + AC扫描

## 数据源分析

### 1. 人工审核数据 (data/human_review_processed/)

- **文件**: `human_review_all.jsonl`
- **数量**: 275条
- **质量**: 高质量人工标注
- **标签**: violation (label=2)
- **特点**: 包含详细的推理说明和置信度

### 2. LLM诊断数据 (data/llm_diagnosis_processed/)

- **文件**: `llm_diagnosis_all.jsonl`
- **数量**: 2000+条
- **质量**: 大模型智能诊断
- **标签**: suspicious (label=1)
- **特点**: 覆盖范围广，包含推理过程

### 3. AC扫描数据 (data/tsv/)

- **文件**: `batch_scan.tsv`
- **数量**: 大量敏感词匹配结果
- **质量**: 精确匹配，需要语义判断
- **标签**: normal (label=0)
- **特点**: 包含敏感词上下文

## 采样策略

### 核心原则

1. **优先包含高质量数据**: 人工审核 > LLM诊断 > AC扫描
2. **避免数据重复**: 确保PID不重复
3. **平衡标签分布**: 合理分配三类标签
4. **保持数据质量**: 确保每条数据都有足够的上下文信息

### 具体策略

#### 步骤1: 违规数据 (label=2)

- **来源**: 人工审核数据
- **数量**: 275条 (全部包含)
- **处理**: 直接使用，无需额外处理
- **理由**: 最高质量的人工标注数据

#### 步骤2: 疑似数据 (label=1)

- **来源**: LLM诊断数据中不重复的部分
- **数量**: 约2000条
- **处理**: 排除已在人工审核中出现的PID
- **理由**: 大模型诊断，质量较高

#### 步骤3: 合规数据 (label=0)

- **来源**: AC扫描数据
- **数量**: 补充到6000条
- **处理**: 随机采样，排除已使用的PID
- **理由**: 提供负样本，平衡数据集

## 数据集划分

### 划分比例

- **训练集**: 80% (4800条)
- **验证集**: 10% (600条)
- **测试集**: 10% (600条)

### 划分策略

1. **按类别分别划分**: 确保每个集合都包含三类数据
2. **随机打乱**: 使用固定随机种子确保可重现
3. **保持比例**: 每个集合中三类数据的比例保持一致

## 数据格式

### 输入格式

```json
{
  "text": "原始文本内容",
  "label": 0|1|2,
  "meta": {
    "pid": "帖子ID",
    "hit_word": "敏感词",
    "confidence": 0.0-1.0,
    "reasoning": "推理说明",
    "source": "数据来源",
    "source_file": "源文件名"
  }
}
```

### 输出文件

- `data/sampled/train.jsonl` - 训练集
- `data/sampled/val.jsonl` - 验证集
- `data/sampled/test.jsonl` - 测试集
- `data/sampled/dataset_stats.json` - 统计信息

## 标签定义

### Label=0: 合规 (normal)

- **定义**: 内容正常，不涉及敏感信息
- **来源**: AC扫描数据
- **特点**: 包含敏感词但上下文正常

### Label=1: 疑似 (suspicious)

- **定义**: 可能涉及敏感内容，需要进一步判断
- **来源**: LLM诊断数据
- **特点**: 大模型认为有风险但未确认

### Label=2: 违规 (violation)

- **定义**: 明确涉及敏感或违规内容
- **来源**: 人工审核数据
- **特点**: 经过人工确认的违规内容

## 质量保证

### 数据完整性

- ✅ 人工审核数据275条完全包含
- ✅ LLM诊断数据覆盖范围广
- ✅ AC扫描数据提供充足负样本

### 数据一致性

- ✅ 统一的数据格式
- ✅ 标准化的标签定义
- ✅ 完整的元数据信息

### 数据平衡性

- ✅ 三类数据合理分布
- ✅ 避免数据倾斜
- ✅ 保证训练效果

## 执行计划

### 阶段1: 数据准备 ✅

- [x] 验证人工审核数据完整性
- [x] 验证LLM诊断数据质量
- [x] 验证AC扫描数据格式

### 阶段2: 采样执行 (待执行)

- [ ] 运行采样脚本
- [ ] 验证数据分布
- [ ] 检查数据质量

### 阶段3: 数据集生成 (待执行)

- [ ] 生成训练/验证/测试集
- [ ] 保存统计信息
- [ ] 验证数据集完整性

## 技术实现

### 核心脚本

- **文件**: `scripts/generate_training_data.py`
- **功能**: 实现完整的采样和划分逻辑
- **输出**: 标准化的训练数据集

### 关键函数

- `load_data()`: 加载三个数据源
- `classify_data()`: 分类标注数据
- `split_dataset()`: 划分数据集
- `save_datasets()`: 保存结果

## 验证方法

### 数据质量验证

```bash
# 检查数据分布
python -c "import json; data=[json.loads(l) for l in open('data/sampled/train.jsonl')]; print('训练集大小:', len(data))"

# 检查标签分布
python -c "import json; from collections import Counter; data=[json.loads(l) for l in open('data/sampled/train.jsonl')]; print('标签分布:', Counter([d['label'] for d in data]))"
```

### 格式验证

```bash
# 验证JSONL格式
python -c "import json; [json.loads(l) for l in open('data/sampled/train.jsonl')]; print('格式正确')"
```

## 注意事项

1. **数据备份**: 采样前备份原始数据
2. **随机种子**: 使用固定种子确保可重现
3. **内存管理**: 大数据量处理时注意内存使用
4. **错误处理**: 添加适当的异常处理机制

## 相关文档

- [项目状态总结](./project-status-summary.md)
- [批量扫描修复](../fix-batch-scan-issues.md)
- [Bert+LoRa FAQ](../bert-lora-faq.md)

---

**开发状态**: 方案已确认  
**最后更新**: 2025-07-02  
**下一步**: 执行数据采样
