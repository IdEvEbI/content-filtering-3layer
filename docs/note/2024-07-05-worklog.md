# 2024-07-05 工作日报

## 昨日工作总结

1. 整理标注数据，为模型训练做准备。
2. 编写并多次修改 `src/semantic_service/train.py`，在本地测试模型训练流程。
3. 用 `src/semantic_service/inference.py` 验证模型效果，确保本地流程跑通，降低云端调试成本。
4. 购买并配置阿里云 GPU 服务器，部署代码仓库。
5. 多次修改 `train.py`，最终实现模型能在云端正常训练。
6. 修改 `inference.py`，用本地基座模型进行推理验证。

## 昨日遇到的问题与解决

1. **本地模型反复修改**：多次调整训练和推理脚本，详细过程见 `docs/note/project-status-summary.md`。
2. **阿里云服务器相关问题**：
   - 无法访问 Github：通过本地打包 zip 上传代码解决。
   - 未安装显卡驱动：手动安装 NVIDIA 驱动并重启服务器。
   - 环境管理：用 Conda 替代 venv，创建干净的虚拟环境。
   - 无法访问 HuggingFace：本地下载 `chinese-roberta-wwm-ext`，上传到服务器，保证离线加载。
   - 多次修改 train.py 适配本地/云端环境、离线模型加载、metrics 兼容等问题。
   - inference.py 本地基座适配，推理时指定本地基座模型，彻底离线推理。
   - 数据不均衡问题：训练数据中 violation（违规）样本太少，导致模型对敏感词检测效果不佳。

## 今日工作计划

1. 整理昨日工作日报（本文件），并记录今日计划。
2. 基于昨日经验，完善 `docs/note/aliyun-lora-train-deploy.md`，补充云平台对比（如 AWS、GCP 方案）。
3. 撰写 Conda vs venv 技术笔记，说明两者区别及适用场景。
4. 整合优化 `train.py` 和 `inference.py`，支持本地/远程灵活切换。
5. （如有精力）测试 AWS/GCP 训练流程，记录差异。
6. 深度讨论 BERT 方案与三层过滤系统的可行性、风险点及下一步技术路线。
7. 所有工作均在 `feature/lora-train-refactor` 分支推进，避免污染主线。

---

如有补充或调整，随时记录在本文件。
